{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Attack Analysis for MAMBA vs CNN Models\n",
    "This notebook implements and analyzes membership inference attacks against MAMBA and CNN model checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "from model import ImageMamba, ModelArgs, SmallerComparableCNN\n",
    "from data_loader import load_cifar10, get_class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "# Attack Model Architecture\n",
    "class AttackModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.input_size = num_classes * 2  # Concatenated logits and probabilities\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(32, 2)  # Binary classification: member vs non-member\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Attack Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MembershipInferenceAttack:\n",
    "    def __init__(self, target_model, device='cuda'):\n",
    "        self.target_model = target_model\n",
    "        self.attack_model = AttackModel().to(device)\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.attack_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        \n",
    "    def prepare_attack_data(self, train_loader, test_loader):\n",
    "        \"\"\"Prepare data for attack by collecting model outputs\"\"\"\n",
    "        attack_inputs = []\n",
    "        attack_labels = []\n",
    "        \n",
    "        self.target_model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Process training data (members)\n",
    "            for data, _ in train_loader:\n",
    "                data = data.to(self.device)\n",
    "                logits, probs = self.target_model(data)\n",
    "                features = torch.cat([logits, probs], dim=1)\n",
    "                attack_inputs.append(features.cpu())\n",
    "                attack_labels.extend([1] * data.size(0))\n",
    "                \n",
    "            # Process test data (non-members)    \n",
    "            for data, _ in test_loader:\n",
    "                data = data.to(self.device)\n",
    "                logits, probs = self.target_model(data)\n",
    "                features = torch.cat([logits, probs], dim=1)\n",
    "                attack_inputs.append(features.cpu())\n",
    "                attack_labels.extend([0] * data.size(0))\n",
    "        \n",
    "        X = torch.cat(attack_inputs)\n",
    "        y = torch.tensor(attack_labels, dtype=torch.long)\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    def train_attack(self, train_loader, test_loader, epochs=10):\n",
    "        \"\"\"Train the attack model\"\"\"\n",
    "        X, y = self.prepare_attack_data(train_loader, test_loader)\n",
    "        \n",
    "        # Balance dataset\n",
    "        member_idx = (y == 1).nonzero().squeeze()\n",
    "        non_member_idx = (y == 0).nonzero().squeeze()\n",
    "        \n",
    "        min_size = min(len(member_idx), len(non_member_idx))\n",
    "        member_idx = member_idx[:min_size]\n",
    "        non_member_idx = non_member_idx[:min_size]\n",
    "        \n",
    "        balanced_idx = torch.cat([member_idx, non_member_idx])\n",
    "        X = X[balanced_idx]\n",
    "        y = y[balanced_idx]\n",
    "        \n",
    "        # Split into train/val\n",
    "        perm = torch.randperm(len(X))\n",
    "        train_size = int(0.8 * len(X))\n",
    "        \n",
    "        train_idx = perm[:train_size]\n",
    "        val_idx = perm[train_size:]\n",
    "        \n",
    "        train_data = TensorDataset(X[train_idx], y[train_idx])\n",
    "        val_data = TensorDataset(X[val_idx], y[val_idx])\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=64)\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        patience = 5\n",
    "        epochs_no_improve = 0\n",
    "        \n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            self.attack_model.train()\n",
    "            train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.attack_model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += predicted.eq(labels).sum().item()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_acc = 100.0 * train_correct / train_total\n",
    "            train_accs.append(train_acc)\n",
    "            \n",
    "            # Validation\n",
    "            self.attack_model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    outputs = self.attack_model(inputs)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            val_acc = 100.0 * val_correct / val_total\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%')\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "            \n",
    "            if epochs_no_improve == patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "                break\n",
    "                \n",
    "        return train_accs, val_accs\n",
    "\n",
    "def evaluate_attack(attack_model, target_model, data_loader, is_member=True, device='cuda'):\n",
    "    \"\"\"Evaluate attack model performance\"\"\"\n",
    "    attack_model.eval()\n",
    "    target_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in data_loader:\n",
    "            data = data.to(device)\n",
    "            logits, probs = target_model(data)\n",
    "            features = torch.cat([logits, probs], dim=1)\n",
    "            \n",
    "            outputs = attack_model(features)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            labels = torch.full((data.size(0),), 1 if is_member else 0, device=device)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def analyze_checkpoint(model_name, checkpoint_path, model, train_loader, test_loader, device='cuda'):\n",
    "    \"\"\"Analyze a single checkpoint\"\"\"\n",
    "    print(f\"\\nAnalyzing {model_name} checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Train attack model\n",
    "    attack = MembershipInferenceAttack(model, device)\n",
    "    train_accs, val_accs = attack.train_attack(train_loader, test_loader)\n",
    "    \n",
    "    # Evaluate attack performance\n",
    "    train_acc = evaluate_attack(attack.attack_model, model, train_loader, True, device)\n",
    "    test_acc = evaluate_attack(attack.attack_model, model, test_loader, False, device)\n",
    "    \n",
    "    return {\n",
    "        'checkpoint': checkpoint_path,\n",
    "        'attack_train_history': train_accs,\n",
    "        'attack_val_history': val_accs,\n",
    "        'member_accuracy': train_acc,\n",
    "        'non_member_accuracy': test_acc,\n",
    "        'attack_success': (train_acc + test_acc) / 2\n",
    "    }\n",
    "\n",
    "def plot_attack_results(mamba_results, cnn_results, save_dir='inference_attack_results'):\n",
    "    \"\"\"Plot comparison of attack results\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Attack success rate over training progress\n",
    "    plt.subplot(2, 1, 1)\n",
    "    mamba_epochs = [int(r['checkpoint'].split('_')[-1].split('.')[0]) for r in mamba_results]\n",
    "    mamba_success = [r['attack_success'] for r in mamba_results]\n",
    "    cnn_success = [r['attack_success'] for r in cnn_results]\n",
    "    \n",
    "    plt.plot(mamba_epochs, mamba_success, 'b-o', label='MAMBA')\n",
    "    plt.plot(mamba_epochs, cnn_success, 'r-o', label='CNN')\n",
    "    plt.axhline(y=50, color='gray', linestyle='--', label='Random Guess')\n",
    "    \n",
    "    plt.title('Membership Inference Attack Success Rate vs Training Progress')\n",
    "    plt.xlabel('Training Epochs')\n",
    "    plt.ylabel('Attack Success Rate (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 2: Member vs Non-member accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    width = 0.35\n",
    "    indices = np.arange(len(mamba_epochs))\n",
    "    \n",
    "    plt.bar(indices - width/2, [r['member_accuracy'] for r in mamba_results], \n",
    "           width, label='MAMBA Member', color='blue', alpha=0.6)\n",
    "    plt.bar(indices + width/2, [r['member_accuracy'] for r in cnn_results],\n",
    "           width, label='CNN Member', color='red', alpha=0.6)\n",
    "    \n",
    "    plt.bar(indices - width/2, [r['non_member_accuracy'] for r in mamba_results],\n",
    "           width, bottom=[r['member_accuracy'] for r in mamba_results],\n",
    "           label='MAMBA Non-member', color='blue', alpha=0.3)\n",
    "    plt.bar(indices + width/2, [r['non_member_accuracy'] for r in cnn_results],\n",
    "           width, bottom=[r['member_accuracy'] for r in cnn_results],\n",
    "           label='CNN Non-member', color='red', alpha=0.3)\n",
    "    \n",
    "    plt.xticks(indices, mamba_epochs, rotation=45)\n",
    "    plt.title('Attack Performance on Members vs Non-members')\n",
    "    plt.xlabel('Training Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'membership_inference_analysis.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Save numerical results\n",
    "    results = {\n",
    "        'epochs': mamba_epochs,\n",
    "        'mamba_success_rates': mamba_success,\n",
    "        'cnn_success_rates': cnn_success,\n",
    "        'mamba_member_acc': [r['member_accuracy'] for r in mamba_results],\n",
    "        'mamba_nonmember_acc': [r['non_member_accuracy'] for r in mamba_results],\n",
    "        'cnn_member_acc': [r['member_accuracy'] for r in cnn_results],\n",
    "        'cnn_nonmember_acc': [r['non_member_accuracy'] for r in cnn_results]\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'attack_results.json'), 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    train_loader, test_loader, _, _, _, _ = load_cifar10(batch_size=64, seed=42)\n",
    "    \n",
    "    # Initialize models\n",
    "    mamba_args = ModelArgs(d_model=64, n_layer=4, vocab_size=0)\n",
    "    mamba_model = ImageMamba(mamba_args, num_classes=10)\n",
    "    \n",
    "    cnn_model = SmallerComparableCNN()\n",
    "    \n",
    "    # Define checkpoints to analyze (every 100 epochs from checkpoint frequency)\n",
    "    checkpoints = range(100, 1501, 100)\n",
    "    \n",
    "    mamba_results = []\n",
    "    cnn_results = []\n",
    "    \n",
    "    # Analyze MAMBA checkpoints\n",
    "    print(\"\\nAnalyzing MAMBA checkpoints...\")\n",
    "    for epoch in checkpoints:\n",
    "        checkpoint_path = os.path.join('mamba_checkpoints', f'model_epoch_{epoch}.pt')\n",
    "        result = analyze_checkpoint('MAMBA', checkpoint_path, mamba_model, \n",
    "                                 train_loader, test_loader, device)\n",
    "        mamba_results.append(result)\n",
    "    \n",
    "    # Analyze CNN checkpoints\n",
    "    print(\"\\nAnalyzing CNN checkpoints...\")\n",
    "    for epoch in checkpoints:\n",
    "        checkpoint_path = os.path.join('cnn_checkpoints', f'model_epoch_{epoch}.pt')\n",
    "        result = analyze_checkpoint('CNN', checkpoint_path, cnn_model,\n",
    "                                 train_loader, test_loader, device)\n",
    "        cnn_results.append(result)\n",
    "    \n",
    "    # Plot and save results\n",
    "    plot_attack_results(mamba_results, cnn_results)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nFinal Attack Results Summary:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nMAMBA Model:\")\n",
    "    print(f\"Final checkpoint attack success rate: {mamba_results[-1]['attack_success']:.2f}%\")\n",
    "    print(f\"Member identification accuracy: {mamba_results[-1]['member_accuracy']:.2f}%\")\n",
    "    print(f\"Non-member identification accuracy: {mamba_results[-1]['non_member_accuracy']:.2f}%\")\n",
    "    \n",
    "    print(\"\\nCNN Model:\")\n",
    "    print(f\"Final checkpoint attack success rate: {cnn_results[-1]['attack_success']:.2f}%\")\n",
    "    print(f\"Member identification accuracy: {cnn_results[-1]['member_accuracy']:.2f}%\")\n",
    "    print(f\"Non-member identification accuracy: {cnn_results[-1]['non_member_accuracy']:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
