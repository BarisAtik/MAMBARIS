{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python --version\n",
    "#!pip install --upgrade pip\n",
    "#!pip uninstall keras tensorflow\n",
    "#!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from model import ModelArgs, ImageMamba\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from model import ImageMamba, ModelArgs\n",
    "from __future__ import print_function\n",
    "from data_loader import load_cifar10, get_class_names # For consistent data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, X_train, X_test, Y_train, Y_test = load_cifar10(batch_size=64, seed=42)\n",
    "class_names = get_class_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA available? {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Sep_12_02:55:00_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.77\n",
      "Build cuda_12.6.r12.6/compiler.34841621_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints & measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from check_and_measure import evaluate_model, save_checkpoint, load_last_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mamba(model, train_loader, test_loader, num_epochs=2000, device='cuda',\n",
    "               checkpoint_dir='mamba_checkpoints', checkpoint_freq=100):\n",
    "   \"\"\"Train model with comprehensive metrics tracking.\"\"\"\n",
    "   \n",
    "   # Check if directory exists and contains files\n",
    "   if os.path.exists(checkpoint_dir) and os.listdir(checkpoint_dir):\n",
    "       raise RuntimeError(\n",
    "           f\"Directory {checkpoint_dir} already contains files. Using this directory would overwrite \"\n",
    "           \"existing training data. To prevent data loss, please use an empty directory \"\n",
    "           \"or use continue_training() to resume from the last checkpoint.\"\n",
    "       )\n",
    "       \n",
    "   os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "   criterion = nn.CrossEntropyLoss()\n",
    "   optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "   \n",
    "   scheduler = OneCycleLR(\n",
    "       optimizer,\n",
    "       max_lr=1e-3,\n",
    "       epochs=num_epochs,\n",
    "       steps_per_epoch=len(train_loader),\n",
    "       pct_start=0.3,\n",
    "       anneal_strategy='cos'\n",
    "   )\n",
    "   \n",
    "   metrics = {\n",
    "       'train_losses': [], 'test_losses': [],\n",
    "       'train_accuracies': [], 'test_accuracies': [],\n",
    "       'train_confidences': [], 'test_confidences': [],\n",
    "       'epoch_train_confidences': [], 'epoch_test_confidences': []\n",
    "   }\n",
    "   \n",
    "   for epoch in range(num_epochs):\n",
    "       model.train()\n",
    "       running_loss = 0.0\n",
    "       running_correct = 0\n",
    "       total_samples = 0\n",
    "       train_confidences = []\n",
    "       \n",
    "       for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "           inputs, labels = inputs.to(device), labels.to(device)\n",
    "           optimizer.zero_grad()\n",
    "           \n",
    "           logits, probabilities = model(inputs)\n",
    "           loss = criterion(logits, labels)\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "           scheduler.step()\n",
    "           \n",
    "           _, predicted = torch.max(logits, 1)\n",
    "           confidence, _ = torch.max(probabilities, 1)\n",
    "           \n",
    "           running_loss += loss.item()\n",
    "           running_correct += (predicted == labels).sum().item()\n",
    "           total_samples += labels.size(0)\n",
    "           train_confidences.extend(confidence.detach().cpu().numpy())\n",
    "       \n",
    "       train_loss = running_loss / len(train_loader)\n",
    "       train_accuracy = 100 * running_correct / total_samples\n",
    "       train_avg_confidence = np.mean(train_confidences)\n",
    "       \n",
    "       test_loss, test_accuracy, test_avg_confidence, test_confidences = evaluate_model(\n",
    "           model, test_loader, criterion, device)\n",
    "       \n",
    "       metrics['train_losses'].append(train_loss)\n",
    "       metrics['test_losses'].append(test_loss)\n",
    "       metrics['train_accuracies'].append(train_accuracy)\n",
    "       metrics['test_accuracies'].append(test_accuracy)\n",
    "       metrics['train_confidences'].append(train_avg_confidence)\n",
    "       metrics['test_confidences'].append(test_avg_confidence)\n",
    "       metrics['epoch_train_confidences'].append(train_confidences)\n",
    "       metrics['epoch_test_confidences'].append(test_confidences)\n",
    "       \n",
    "       print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "       print(f'Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Confidence: {train_avg_confidence:.4f}')\n",
    "       print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Confidence: {test_avg_confidence:.4f}')\n",
    "       \n",
    "       if (epoch + 1) % checkpoint_freq == 0:\n",
    "           checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pt')\n",
    "           save_checkpoint(model, optimizer, scheduler, epoch, metrics, checkpoint_path)\n",
    "           \n",
    "           metrics_path = os.path.join(checkpoint_dir, 'training_metrics.json')\n",
    "           json_metrics = {\n",
    "               'train_losses': [float(x) for x in metrics['train_losses']],\n",
    "               'test_losses': [float(x) for x in metrics['test_losses']],\n",
    "               'train_accuracies': [float(x) for x in metrics['train_accuracies']],\n",
    "               'test_accuracies': [float(x) for x in metrics['test_accuracies']],\n",
    "               'train_confidences': [float(x) for x in metrics['train_confidences']],\n",
    "               'test_confidences': [float(x) for x in metrics['test_confidences']],\n",
    "               'current_epoch': epoch + 1\n",
    "           }\n",
    "           with open(metrics_path, 'w') as f:\n",
    "               json.dump(json_metrics, f, indent=4)\n",
    "   \n",
    "   return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters for overfitting\n",
    "d_model = 128\n",
    "n_layer = 8\n",
    "num_classes = 10\n",
    "\n",
    "# Initialize model\n",
    "model_args = ModelArgs(d_model=d_model, n_layer=n_layer, vocab_size=0)\n",
    "model = ImageMamba(model_args, num_classes=num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Directory mamba_checkpoints already contains files. Using this directory would overwrite existing training data. To prevent data loss, please use an empty directory or use continue_training() to resume from the last checkpoint.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mamba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mtrain_mamba\u001b[1;34m(model, train_loader, test_loader, num_epochs, device, checkpoint_dir, checkpoint_freq)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Check if directory exists and contains files\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_dir) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(checkpoint_dir):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already contains files. Using this directory would overwrite \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting training data. To prevent data loss, please use an empty directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor use continue_training() to resume from the last checkpoint.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(checkpoint_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Directory mamba_checkpoints already contains files. Using this directory would overwrite existing training data. To prevent data loss, please use an empty directory or use continue_training() to resume from the last checkpoint."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "metrics = train_mamba(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=2000,\n",
    "    device=device,\n",
    "    checkpoint_freq=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash\n",
    "If there was a crash. Which can be when dealing with so many epochs, one can continue from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_training(model, train_loader, test_loader, checkpoint_dir, target_epochs=2000, device='cuda'):\n",
    "    \"\"\"Continue training from last checkpoint.\"\"\"\n",
    "    checkpoint, last_epoch = load_last_checkpoint(checkpoint_dir)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-3,\n",
    "        epochs=target_epochs - last_epoch,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "    \n",
    "    if checkpoint['scheduler_state_dict']:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Load existing metrics\n",
    "    with open(os.path.join(checkpoint_dir, 'training_metrics.json'), 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    complete_metrics = {\n",
    "        'train_losses': metrics['train_losses'],\n",
    "        'test_losses': metrics['test_losses'],\n",
    "        'train_accuracies': metrics['train_accuracies'],\n",
    "        'test_accuracies': metrics['test_accuracies'],\n",
    "        'train_confidences': metrics['train_confidences'],\n",
    "        'test_confidences': metrics['test_confidences'],\n",
    "        'epoch_train_confidences': checkpoint['metrics']['epoch_train_confidences'],\n",
    "        'epoch_test_confidences': checkpoint['metrics']['epoch_test_confidences']\n",
    "    }\n",
    "    \n",
    "    print(f\"Continuing training from epoch {last_epoch} to {target_epochs}\")\n",
    "    \n",
    "    for epoch in range(last_epoch, target_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        total_samples = 0\n",
    "        train_confidences = []\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch [{epoch+1}/{target_epochs}]'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            logits, probabilities = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            confidence, _ = torch.max(probabilities, 1)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            train_confidences.extend(confidence.detach().cpu().numpy())\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * running_correct / total_samples\n",
    "        train_avg_confidence = np.mean(train_confidences)\n",
    "        \n",
    "        test_loss, test_accuracy, test_avg_confidence, test_confidences = evaluate_model(\n",
    "            model, test_loader, criterion, device)\n",
    "        \n",
    "        complete_metrics['train_losses'].append(train_loss)\n",
    "        complete_metrics['test_losses'].append(test_loss)\n",
    "        complete_metrics['train_accuracies'].append(train_accuracy)\n",
    "        complete_metrics['test_accuracies'].append(test_accuracy)\n",
    "        complete_metrics['train_confidences'].append(train_avg_confidence)\n",
    "        complete_metrics['test_confidences'].append(test_avg_confidence)\n",
    "        complete_metrics['epoch_train_confidences'].append(train_confidences)\n",
    "        complete_metrics['epoch_test_confidences'].append(test_confidences)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Confidence: {train_avg_confidence:.4f}')\n",
    "        print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Confidence: {test_avg_confidence:.4f}')\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pt')\n",
    "            save_checkpoint(model, optimizer, scheduler, epoch, complete_metrics, checkpoint_path)\n",
    "            \n",
    "            json_metrics = {\n",
    "                'train_losses': [float(x) for x in complete_metrics['train_losses']],\n",
    "                'test_losses': [float(x) for x in complete_metrics['test_losses']],\n",
    "                'train_accuracies': [float(x) for x in complete_metrics['train_accuracies']],\n",
    "                'test_accuracies': [float(x) for x in complete_metrics['test_accuracies']],\n",
    "                'train_confidences': [float(x) for x in complete_metrics['train_confidences']],\n",
    "                'test_confidences': [float(x) for x in complete_metrics['test_confidences']],\n",
    "                'current_epoch': epoch + 1\n",
    "            }\n",
    "            with open(os.path.join(checkpoint_dir, 'training_metrics.json'), 'w') as f:\n",
    "                json.dump(json_metrics, f, indent=4)\n",
    "    \n",
    "    return complete_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last completed epoch: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baris\\masterthesis\\MAMBARIS\\notebooks\\check_and_measure.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training from epoch 900 to 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [901/2000]:  69%|██████▉   | 543/782 [00:53<00:20, 11.87it/s]"
     ]
    }
   ],
   "source": [
    "with open('mamba_checkpoints/training_metrics.json', 'r') as f:\n",
    "   metrics = json.load(f)\n",
    "print(f\"Last completed epoch: {metrics['current_epoch']}\")\n",
    "\n",
    "metrics = continue_training(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    checkpoint_dir='mamba_checkpoints',\n",
    "    target_epochs=2000,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
