{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def save_pytorch_model(model, filepath, epoch=None):\n",
    "    \"\"\"\n",
    "    Save a PyTorch model to disk, including both architecture and weights.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model (nn.Module)\n",
    "        filepath: Path to save the model\n",
    "        epoch: Optional epoch number to include in the save\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)\n",
    "    \n",
    "    # Prepare the save dictionary\n",
    "    save_dict = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_args': model.args,  # Saving the model arguments\n",
    "        'epoch': epoch if epoch is not None else None\n",
    "    }\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(save_dict, filepath)\n",
    "    print(f\"Model saved successfully to {filepath}\")\n",
    "\n",
    "def load_pytorch_model(filepath):\n",
    "    \"\"\"\n",
    "    Load a PyTorch model from disk.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the saved model\n",
    "        \n",
    "    Returns:\n",
    "        model: Loaded PyTorch model\n",
    "        epoch: Epoch number when the model was saved (if available)\n",
    "    \"\"\"\n",
    "    # Load the save dictionary\n",
    "    save_dict = torch.load(filepath)\n",
    "    \n",
    "    # Create a new model instance with the saved arguments\n",
    "    model = ImageMamba(args=save_dict['model_args'], num_classes=1000)  # Adjust num_classes as needed\n",
    "    \n",
    "    # Load the state dictionary\n",
    "    model.load_state_dict(save_dict['model_state_dict'])\n",
    "    \n",
    "    return model, save_dict.get('epoch')\n",
    "\n",
    "# Example usage:\n",
    "# Saving the model\n",
    "# save_pytorch_model(complex_model, '25epoch_complex_model.pt', epoch=25)\n",
    "\n",
    "# Loading the model\n",
    "# loaded_model, epoch = load_pytorch_model('25epoch_complex_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New dataset\n",
    "Find new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.20\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.18.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: keras in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras tensorflow\n",
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==3.6 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from keras==3.6) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from optree->keras==3.6) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from rich->keras==3.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from rich->keras==3.6) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\baris\\masterthesis\\mambaris\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras==3.6) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.datasets import cifar10\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from model import Mamba, ModelArgs  # Import your custom Mamba implementation\n",
    "# Assuming the model classes are defined in `model.py`\n",
    "from model import ImageMamba, ModelArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 data\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Reshape and preprocess the CIFAR-10 dataset for PyTorch models\n",
    "X_train = X_train.transpose(0, 3, 1, 2)  # Shape: (batch_size, channels, height, width)\n",
    "X_test = X_test.transpose(0, 3, 1, 2)\n",
    "\n",
    "# Convert data to float and normalize pixel values in the range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the train/test data into PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "# Create PyTorch datasets and data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the unique class names for CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageMamba(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x ImageResidualBlock(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (norm_f): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model parameters\n",
    "d_model = 64\n",
    "n_layer = 4\n",
    "num_classes = 10  # CIFAR-10 has 10 classes\n",
    "\n",
    "# Create an instance of ModelArgs\n",
    "model_args = ModelArgs(d_model=d_model, n_layer=n_layer, vocab_size=0)  # vocab_size is unused here\n",
    "\n",
    "# Instantiate the ImageMamba model\n",
    "model = ImageMamba(model_args, num_classes=num_classes)\n",
    "\n",
    "# Set the device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MAMBA on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Sep_12_02:55:00_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.77\n",
      "Build cuda_12.6.r12.6/compiler.34841621_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.9929\n",
      "Epoch [2/10], Loss: 1.8012\n",
      "Epoch [3/10], Loss: 1.7019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 28\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits, probabilities = model(inputs)  # Unpack the logits and probabilities\n",
    "\n",
    "        # Flatten labels if they are not already\n",
    "        labels = labels.view(-1)  # Flatten the labels to [batch_size]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)  # Use logits for loss computation\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model + testing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_prob = []  # List to store probabilities\n",
    "\n",
    "# Test the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataset:  # Use test_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_percentages = np.array(y_prob) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages):\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_percentages[i][class_index]:.2f}%\")\n",
    "\n",
    "# Switch to evaluation mode for training data\n",
    "model.eval()\n",
    "y_pred_train = []\n",
    "y_true_train = []\n",
    "y_prob_train = []  # List to store probabilities\n",
    "\n",
    "# Test the model on training data\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_dataset:  # Use train_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred_train.extend(predicted.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "        y_prob_train.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
    "print(f'Accuracy on the training set: {accuracy_train:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_train_percentages = np.array(y_prob_train) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages) for training data:\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true_train[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_train_percentages[i][class_index]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probabilities for the correct class on the test data\n",
    "correct_class_probs_test = [y_prob[i][y_true[i]] for i in range(len(y_true))]\n",
    "average_prob_correct_class_test = np.mean(correct_class_probs_test)\n",
    "print(f'Average probability for the correct class on the test data: {average_prob_correct_class_test:.4f}')\n",
    "\n",
    "# Extract probabilities for the correct class on the training data\n",
    "correct_class_probs_train = [y_prob_train[i][y_true_train[i]] for i in range(len(y_true_train))]\n",
    "average_prob_correct_class_train = np.mean(correct_class_probs_train)\n",
    "print(f'Average probability for the correct class on the training data: {average_prob_correct_class_train:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 2, more epochs\n",
    "As we can see there is not much difference between the probabilities of true class predictions on the traindataset instances, and the testdataset instances.\n",
    "\n",
    "This might indicate that the dataset was hard easy for 10 epochs, lets add 15 more epochs, to get to a total of 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # Forward pass\n",
    "        logits, probabilities = model(inputs)  # Unpack the logits and probabilities\n",
    "\n",
    "        # Flatten labels if they are not already\n",
    "        labels = labels.view(-1)  # Flatten the labels to [batch_size]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)  # Use logits for loss computation\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_prob = []  # List to store probabilities\n",
    "\n",
    "# Test the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataset:  # Use test_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_percentages = np.array(y_prob) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages):\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_percentages[i][class_index]:.2f}%\")\n",
    "\n",
    "# Switch to evaluation mode for training data\n",
    "model.eval()\n",
    "y_pred_train = []\n",
    "y_true_train = []\n",
    "y_prob_train = []  # List to store probabilities\n",
    "\n",
    "# Test the model on training data\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_dataset:  # Use train_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred_train.extend(predicted.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "        y_prob_train.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
    "print(f'Accuracy on the training set: {accuracy_train:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_train_percentages = np.array(y_prob_train) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages) for training data:\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true_train[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_train_percentages[i][class_index]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probabilities for the correct class on the test data\n",
    "correct_class_probs_test = [y_prob[i][y_true[i]] for i in range(len(y_true))]\n",
    "average_prob_correct_class_test = np.mean(correct_class_probs_test)\n",
    "print(f'Average probability for the correct class on the test data: {average_prob_correct_class_test:.4f}')\n",
    "\n",
    "# Extract probabilities for the correct class on the training data\n",
    "correct_class_probs_train = [y_prob_train[i][y_true_train[i]] for i in range(len(y_true_train))]\n",
    "average_prob_correct_class_train = np.mean(correct_class_probs_train)\n",
    "print(f'Average probability for the correct class on the training data: {average_prob_correct_class_train:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see still no significant diffirence, lets make a stronger model, and train more epochs to achieve a loss close to 0, and then try inference again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 3, complex model\n",
    "To get a much lower loss, we will both increase the number of epochs and make the model more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageMamba(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layers): ModuleList(\n",
       "    (0-7): 8 x ImageResidualBlock(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (norm_f): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model parameters\n",
    "d_model = 128\n",
    "n_layer = 8\n",
    "num_classes = 10  # CIFAR-10 has 10 classes\n",
    "\n",
    "# Create an instance of ModelArgs\n",
    "model_args = ModelArgs(d_model=d_model, n_layer=n_layer, vocab_size=0)  # vocab_size is unused here\n",
    "\n",
    "# Instantiate the ImageMamba model\n",
    "complex_model = ImageMamba(model_args, num_classes=num_classes)\n",
    "\n",
    "# Set the device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "complex_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 1.9134\n",
      "Epoch [2/25], Loss: 1.6960\n",
      "Epoch [3/25], Loss: 1.5853\n",
      "Epoch [4/25], Loss: 1.4995\n",
      "Epoch [5/25], Loss: 1.4248\n",
      "Epoch [6/25], Loss: 1.3690\n",
      "Epoch [7/25], Loss: 1.3213\n",
      "Epoch [8/25], Loss: 1.2828\n",
      "Epoch [9/25], Loss: 1.2517\n",
      "Epoch [10/25], Loss: 1.2271\n",
      "Epoch [11/25], Loss: 1.2041\n",
      "Epoch [12/25], Loss: 1.1814\n",
      "Epoch [13/25], Loss: 1.1629\n",
      "Epoch [14/25], Loss: 1.1459\n",
      "Epoch [15/25], Loss: 1.1294\n",
      "Epoch [16/25], Loss: 1.1153\n",
      "Epoch [17/25], Loss: 1.0992\n",
      "Epoch [18/25], Loss: 1.1103\n",
      "Epoch [19/25], Loss: 1.1682\n",
      "Epoch [20/25], Loss: 1.1348\n",
      "Epoch [21/25], Loss: 1.1272\n",
      "Epoch [22/25], Loss: 1.1174\n",
      "Epoch [23/25], Loss: 1.0885\n",
      "Epoch [24/25], Loss: 1.0898\n",
      "Epoch [25/25], Loss: 1.0860\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(complex_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25 \n",
    "for epoch in range(num_epochs):\n",
    "    complex_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits, probabilities = complex_model(inputs)  # Unpack the logits and probabilities\n",
    "\n",
    "        # Flatten labels if they are not already\n",
    "        labels = labels.view(-1)  # Flatten the labels to [batch_size]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)  # Use logits for loss computation\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to ../trained_models/25epoch_complex_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the model after 25 epochs\n",
    "save_pytorch_model(complex_model, '../trained_models/25epoch_complex_model.pt', epoch=25)\n",
    "\n",
    "# Later, to load the model:\n",
    "# loaded_model, epoch = load_pytorch_model('25epoch_complex_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.6134\n",
      "First few predicted class names and their probabilities (in percentages):\n",
      "Instance 1:\n",
      "  Correct Class: cat\n",
      "  Class: airplane, Probability: 0.82%\n",
      "  Class: automobile, Probability: 1.33%\n",
      "  Class: bird, Probability: 6.28%\n",
      "  Class: cat, Probability: 47.06%\n",
      "  Class: deer, Probability: 2.20%\n",
      "  Class: dog, Probability: 10.97%\n",
      "  Class: frog, Probability: 25.96%\n",
      "  Class: horse, Probability: 0.13%\n",
      "  Class: ship, Probability: 4.24%\n",
      "  Class: truck, Probability: 1.03%\n",
      "Instance 2:\n",
      "  Correct Class: ship\n",
      "  Class: airplane, Probability: 4.24%\n",
      "  Class: automobile, Probability: 31.70%\n",
      "  Class: bird, Probability: 0.07%\n",
      "  Class: cat, Probability: 0.04%\n",
      "  Class: deer, Probability: 0.01%\n",
      "  Class: dog, Probability: 0.01%\n",
      "  Class: frog, Probability: 0.01%\n",
      "  Class: horse, Probability: 0.01%\n",
      "  Class: ship, Probability: 52.40%\n",
      "  Class: truck, Probability: 11.52%\n",
      "Instance 3:\n",
      "  Correct Class: ship\n",
      "  Class: airplane, Probability: 8.50%\n",
      "  Class: automobile, Probability: 3.96%\n",
      "  Class: bird, Probability: 0.13%\n",
      "  Class: cat, Probability: 0.04%\n",
      "  Class: deer, Probability: 0.17%\n",
      "  Class: dog, Probability: 0.02%\n",
      "  Class: frog, Probability: 0.02%\n",
      "  Class: horse, Probability: 0.09%\n",
      "  Class: ship, Probability: 82.15%\n",
      "  Class: truck, Probability: 4.93%\n",
      "Instance 4:\n",
      "  Correct Class: airplane\n",
      "  Class: airplane, Probability: 54.22%\n",
      "  Class: automobile, Probability: 4.90%\n",
      "  Class: bird, Probability: 0.82%\n",
      "  Class: cat, Probability: 0.11%\n",
      "  Class: deer, Probability: 0.21%\n",
      "  Class: dog, Probability: 0.01%\n",
      "  Class: frog, Probability: 0.04%\n",
      "  Class: horse, Probability: 0.13%\n",
      "  Class: ship, Probability: 36.81%\n",
      "  Class: truck, Probability: 2.74%\n",
      "Instance 5:\n",
      "  Correct Class: frog\n",
      "  Class: airplane, Probability: 0.01%\n",
      "  Class: automobile, Probability: 0.01%\n",
      "  Class: bird, Probability: 1.06%\n",
      "  Class: cat, Probability: 0.81%\n",
      "  Class: deer, Probability: 8.53%\n",
      "  Class: dog, Probability: 0.23%\n",
      "  Class: frog, Probability: 89.08%\n",
      "  Class: horse, Probability: 0.24%\n",
      "  Class: ship, Probability: 0.01%\n",
      "  Class: truck, Probability: 0.02%\n",
      "Accuracy on the training set: 0.6299\n",
      "First few predicted class names and their probabilities (in percentages) for training data:\n",
      "Instance 1:\n",
      "  Correct Class: frog\n",
      "  Class: airplane, Probability: 0.16%\n",
      "  Class: automobile, Probability: 0.04%\n",
      "  Class: bird, Probability: 6.60%\n",
      "  Class: cat, Probability: 17.57%\n",
      "  Class: deer, Probability: 19.48%\n",
      "  Class: dog, Probability: 5.49%\n",
      "  Class: frog, Probability: 46.36%\n",
      "  Class: horse, Probability: 4.20%\n",
      "  Class: ship, Probability: 0.07%\n",
      "  Class: truck, Probability: 0.03%\n",
      "Instance 2:\n",
      "  Correct Class: truck\n",
      "  Class: airplane, Probability: 0.59%\n",
      "  Class: automobile, Probability: 42.21%\n",
      "  Class: bird, Probability: 0.10%\n",
      "  Class: cat, Probability: 0.47%\n",
      "  Class: deer, Probability: 0.11%\n",
      "  Class: dog, Probability: 0.23%\n",
      "  Class: frog, Probability: 0.03%\n",
      "  Class: horse, Probability: 0.36%\n",
      "  Class: ship, Probability: 3.44%\n",
      "  Class: truck, Probability: 52.45%\n",
      "Instance 3:\n",
      "  Correct Class: truck\n",
      "  Class: airplane, Probability: 9.24%\n",
      "  Class: automobile, Probability: 8.01%\n",
      "  Class: bird, Probability: 1.95%\n",
      "  Class: cat, Probability: 1.93%\n",
      "  Class: deer, Probability: 6.15%\n",
      "  Class: dog, Probability: 2.30%\n",
      "  Class: frog, Probability: 1.32%\n",
      "  Class: horse, Probability: 7.45%\n",
      "  Class: ship, Probability: 16.89%\n",
      "  Class: truck, Probability: 44.76%\n",
      "Instance 4:\n",
      "  Correct Class: deer\n",
      "  Class: airplane, Probability: 0.15%\n",
      "  Class: automobile, Probability: 0.05%\n",
      "  Class: bird, Probability: 3.19%\n",
      "  Class: cat, Probability: 1.73%\n",
      "  Class: deer, Probability: 57.94%\n",
      "  Class: dog, Probability: 0.70%\n",
      "  Class: frog, Probability: 33.84%\n",
      "  Class: horse, Probability: 2.28%\n",
      "  Class: ship, Probability: 0.04%\n",
      "  Class: truck, Probability: 0.08%\n",
      "Instance 5:\n",
      "  Correct Class: automobile\n",
      "  Class: airplane, Probability: 4.48%\n",
      "  Class: automobile, Probability: 45.69%\n",
      "  Class: bird, Probability: 0.06%\n",
      "  Class: cat, Probability: 0.03%\n",
      "  Class: deer, Probability: 0.05%\n",
      "  Class: dog, Probability: 0.02%\n",
      "  Class: frog, Probability: 0.01%\n",
      "  Class: horse, Probability: 0.10%\n",
      "  Class: ship, Probability: 21.62%\n",
      "  Class: truck, Probability: 27.94%\n"
     ]
    }
   ],
   "source": [
    "# Switch to evaluation mode\n",
    "complex_model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_prob = []  # List to store probabilities\n",
    "\n",
    "# Test the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataset:  # Use test_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = complex_model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_percentages = np.array(y_prob) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages):\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_percentages[i][class_index]:.2f}%\")\n",
    "\n",
    "# Switch to evaluation mode for training data\n",
    "complex_model.eval()\n",
    "y_pred_train = []\n",
    "y_true_train = []\n",
    "y_prob_train = []  # List to store probabilities\n",
    "\n",
    "# Test the model on training data\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_dataset:  # Use train_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = complex_model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred_train.extend(predicted.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "        y_prob_train.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
    "print(f'Accuracy on the training set: {accuracy_train:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_train_percentages = np.array(y_prob_train) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages) for training data:\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true_train[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_train_percentages[i][class_index]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average probability for the correct class on the test data: 0.4554\n",
      "Average probability for the correct class on the training data: 0.4649\n"
     ]
    }
   ],
   "source": [
    "# Extract probabilities for the correct class on the test data\n",
    "correct_class_probs_test = [y_prob[i][y_true[i]] for i in range(len(y_true))]\n",
    "average_prob_correct_class_test = np.mean(correct_class_probs_test)\n",
    "print(f'Average probability for the correct class on the test data: {average_prob_correct_class_test:.4f}')\n",
    "\n",
    "# Extract probabilities for the correct class on the training data\n",
    "correct_class_probs_train = [y_prob_train[i][y_true_train[i]] for i in range(len(y_true_train))]\n",
    "average_prob_correct_class_train = np.mean(correct_class_probs_train)\n",
    "print(f'Average probability for the correct class on the training data: {average_prob_correct_class_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in percentage is:  2.050626650452614\n"
     ]
    }
   ],
   "source": [
    "print(\"Difference in percentage is: \", (average_prob_correct_class_train - average_prob_correct_class_test)/average_prob_correct_class_train*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the model started to overfit which is why the loss stopped decreasing, now we will try a different optimiser and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define optimizer with AdamW\n",
    "optimizer = optim.AdamW(complex_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Cosine Annealing Scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# Training Loop with Scheduler\n",
    "num_epochs = 50  # More epochs to ensure convergence\n",
    "for epoch in range(num_epochs):\n",
    "    complex_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits, probabilities = complex_model(inputs)\n",
    "\n",
    "        # Flatten labels if necessary\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Step the scheduler at each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(complex_model, '50epch_complex_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "complex_model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_prob = []  # List to store probabilities\n",
    "\n",
    "# Test the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataset:  # Use test_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = complex_model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_percentages = np.array(y_prob) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages):\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_percentages[i][class_index]:.2f}%\")\n",
    "\n",
    "# Switch to evaluation mode for training data\n",
    "complex_model.eval()\n",
    "y_pred_train = []\n",
    "y_true_train = []\n",
    "y_prob_train = []  # List to store probabilities\n",
    "\n",
    "# Test the model on training data\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_dataset:  # Use train_dataset directly\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits, probabilities = complex_model(inputs)  # Now get both logits and probabilities\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        y_pred_train.extend(predicted.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "        y_prob_train.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
    "print(f'Accuracy on the training set: {accuracy_train:.4f}')\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "y_prob_train_percentages = np.array(y_prob_train) * 100  # Convert probabilities to percentages\n",
    "\n",
    "# Display the first few predicted class names along with their probabilities and the correct class\n",
    "print(\"First few predicted class names and their probabilities (in percentages) for training data:\")\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"  Correct Class: {class_names[y_true_train[i]]}\")\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        print(f\"  Class: {class_name}, Probability: {y_prob_train_percentages[i][class_index]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probabilities for the correct class on the test data\n",
    "correct_class_probs_test = [y_prob[i][y_true[i]] for i in range(len(y_true))]\n",
    "average_prob_correct_class_test = np.mean(correct_class_probs_test)\n",
    "print(f'Average probability for the correct class on the test data: {average_prob_correct_class_test:.4f}')\n",
    "\n",
    "# Extract probabilities for the correct class on the training data\n",
    "correct_class_probs_train = [y_prob_train[i][y_true_train[i]] for i in range(len(y_true_train))]\n",
    "average_prob_correct_class_train = np.mean(correct_class_probs_train)\n",
    "print(f'Average probability for the correct class on the training data: {average_prob_correct_class_train:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
